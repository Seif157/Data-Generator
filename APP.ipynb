{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfeBYJdd_Gy1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_client(api_key: str):\n",
        "    \"\"\"Initialize Gemini with the current stable Flash model\"\"\"\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    # gemini-2.5-flash is the stable production model as of late 2025/2026.\n",
        "    # gemini-flash-latest is an alias that always points to the newest stable Flash model.\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name=\"gemini-2.5-flash\",\n",
        "        generation_config={\"response_mime_type\": \"application/json\"}\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "gOTMtJYhMjp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Single Batch Generation\n",
        "def generate_synthetic_data(\n",
        "    api_key: str,\n",
        "    schema_description: str,\n",
        "    num_records: int,\n",
        "    example_format: str = \"\"\n",
        ") -> tuple:\n",
        "    \"\"\"Generate synthetic records using Gemini JSON mode\"\"\"\n",
        "    try:\n",
        "        model = create_client(api_key)\n",
        "\n",
        "        example_section = f\"\\n\\nExample format:\\n{example_format}\" if example_format else \"\"\n",
        "\n",
        "        # System-style prompt\n",
        "        prompt = f\"\"\"You are a data generation expert.\n",
        "Generate {num_records} synthetic data records based on this schema:\n",
        "{schema_description}\n",
        "{example_section}\n",
        "\n",
        "Requirements:\n",
        "- Return a JSON object with a key \"records\" containing an array of objects.\n",
        "- Each object must match the schema provided.\n",
        "- Ensure data is realistic, diverse, and correctly typed.\n",
        "- Output ONLY the JSON object.\n",
        "\n",
        "Generate exactly {num_records} records.\"\"\"\n",
        "\n",
        "        # Call Gemini\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        # Parse result\n",
        "        raw_data = json.loads(response.text)\n",
        "\n",
        "        # Extract the list from the \"records\" key\n",
        "        if isinstance(raw_data, dict) and \"records\" in raw_data:\n",
        "            data = raw_data[\"records\"]\n",
        "        else:\n",
        "            # Fallback: find the first list in the dictionary\n",
        "            data = next((v for v in raw_data.values() if isinstance(v, list)), [])\n",
        "\n",
        "        df = pd.DataFrame(data).head(num_records)\n",
        "\n",
        "        # Save to temp CSV\n",
        "        fd, temp_path = tempfile.mkstemp(suffix='.csv', prefix='gemini_synth_')\n",
        "        os.close(fd)\n",
        "        df.to_csv(temp_path, index=False)\n",
        "\n",
        "        return df, f\"âœ… Successfully generated {len(df)} records!\", temp_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Gemini Error: {str(e)}\", None"
      ],
      "metadata": {
        "id": "_XpovpSbNB1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Batch Logic (for larger datasets)\n",
        "def generate_batch_data(\n",
        "    api_key: str,\n",
        "    schema_description: str,\n",
        "    total_records: int,\n",
        "    example_format: str = \"\",\n",
        "    batch_size: int = 50\n",
        ") -> tuple:\n",
        "    \"\"\"Consolidate multiple Gemini API calls into one DataFrame\"\"\"\n",
        "    all_data = []\n",
        "    batches = (total_records + batch_size - 1) // batch_size\n",
        "\n",
        "    print(f\"Starting generation of {total_records} records in {batches} batches...\")\n",
        "\n",
        "    for i in range(batches):\n",
        "        remaining = total_records - len(all_data)\n",
        "        records_in_batch = min(batch_size, remaining)\n",
        "\n",
        "        df_batch, status, csv_path = generate_synthetic_data(\n",
        "            api_key, schema_description, records_in_batch, example_format\n",
        "        )\n",
        "\n",
        "        if df_batch is not None:\n",
        "            all_data.extend(df_batch.to_dict('records'))\n",
        "            if os.path.exists(csv_path): os.remove(csv_path) # Cleanup temp batch files\n",
        "            print(f\"Batch {i+1}/{batches} complete...\")\n",
        "        else:\n",
        "            return None, f\"âŒ Failed at batch {i+1}: {status}\", None\n",
        "\n",
        "    # Final Consolidation\n",
        "    final_df = pd.DataFrame(all_data)\n",
        "    fd, temp_path = tempfile.mkstemp(suffix='.csv', prefix='final_gemini_data_')\n",
        "    os.close(fd)\n",
        "    final_df.to_csv(temp_path, index=False)\n",
        "\n",
        "    return final_df, f\"âœ… Generated {len(final_df)} records in {batches} batches!\", temp_path"
      ],
      "metadata": {
        "id": "f219LeilPdTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_api = userdata.get('GOOGLE_API_KEY')\n",
        "# Create Gradio Interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"Synthetic Dataset Generator\", theme=gr.themes.Base()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ðŸ¤– Synthetic Dataset Generator\n",
        "        ### Powered by Google Gemini 1.5 Flash\n",
        "\n",
        "        Create custom synthetic datasets by describing your schema. Gemini will generate realistic data matching your specifications using high-speed JSON mode.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Show API key input only if not found in environment/secrets\n",
        "                if not google_api:\n",
        "                    api_key_input = gr.Textbox(\n",
        "                        label=\"Gemini API Key\",\n",
        "                        type=\"password\",\n",
        "                        placeholder=\"AIza...\",\n",
        "                        info=\"API key not found in Colab Secrets\"\n",
        "                    )\n",
        "                else:\n",
        "                    api_key_input = gr.Textbox(\n",
        "                        label=\"Gemini API Key\",\n",
        "                        type=\"password\",\n",
        "                        value=google_api,\n",
        "                        placeholder=\"Loaded from Secrets\",\n",
        "                        info=\"âœ… API key loaded from environment\",\n",
        "                        interactive=False\n",
        "                    )\n",
        "\n",
        "                schema_input = gr.Textbox(\n",
        "                    label=\"Data Schema Description\",\n",
        "                    placeholder=\"\"\"Example: Generate customer data with:\n",
        "- name (full name)\n",
        "- email (valid email address)\n",
        "- age (between 18-80)\n",
        "- city (US cities)\n",
        "- purchase_amount (between $10-$1000)\n",
        "- join_date (dates in 2023-2024)\"\"\",\n",
        "                    lines=10\n",
        "                )\n",
        "\n",
        "                example_input = gr.Textbox(\n",
        "                    label=\"Example Format (Optional JSON)\",\n",
        "                    placeholder=\"\"\"{\"name\": \"John Doe\", \"email\": \"john@example.com\", \"age\": 35, \"city\": \"New York\"}\"\"\",\n",
        "                    lines=4\n",
        "                )\n",
        "\n",
        "                num_records = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=500,\n",
        "                    value=20,\n",
        "                    step=1,\n",
        "                    label=\"Number of Records\"\n",
        "                )\n",
        "\n",
        "                generate_btn = gr.Button(\"ðŸš€ Generate Dataset\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                status_output = gr.Textbox(label=\"Status\", lines=2)\n",
        "                dataframe_output = gr.Dataframe(\n",
        "                    label=\"Generated Dataset Preview\",\n",
        "                    wrap=True\n",
        "                )\n",
        "                csv_output = gr.File(label=\"Download Full CSV\", type=\"filepath\")\n",
        "\n",
        "        # Examples\n",
        "        gr.Markdown(\"### ðŸ“ Example Schemas\")\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\n",
        "                    \"\"\"Generate employee records with:\n",
        "- employee_id (format: EMP001, EMP002, etc.)\n",
        "- name (full name)\n",
        "- department (Engineering, Sales, Marketing, HR, Finance)\n",
        "- salary (between $40,000-$150,000)\n",
        "- hire_date (between 2020-2024)\n",
        "- performance_rating (1-5)\"\"\",\n",
        "                    20\n",
        "                ],\n",
        "                [\n",
        "                    \"\"\"Generate e-commerce product data with:\n",
        "- product_id (format: PRD-XXXX)\n",
        "- product_name (creative product names)\n",
        "- category (Electronics, Clothing, Home, Books, Sports)\n",
        "- price (between $5-$500)\n",
        "- stock_quantity (between 0-1000)\n",
        "- rating (1.0-5.0)\"\"\",\n",
        "                    25\n",
        "                ],\n",
        "                [\n",
        "                    \"\"\"Generate student records with:\n",
        "- student_id (format: STU2024XXX)\n",
        "- name (full name)\n",
        "- major (Computer Science, Biology, Business, Arts, Engineering)\n",
        "- gpa (2.0-4.0)\n",
        "- year (Freshman, Sophomore, Junior, Senior)\"\"\",\n",
        "                    30\n",
        "                ]\n",
        "            ],\n",
        "            inputs=[schema_input, num_records]\n",
        "        )\n",
        "\n",
        "        def generate_wrapper(api_key, schema, num_rec, example):\n",
        "            # Prioritize input field, then fallback to environment/secrets\n",
        "            final_api_key = api_key or google_api\n",
        "\n",
        "            if not final_api_key:\n",
        "                return None, \"âŒ Please provide your Gemini API key (via Colab Secrets or the input field)\", None\n",
        "            if not schema:\n",
        "                return None, \"âŒ Please describe your data schema\", None\n",
        "\n",
        "            # For larger datasets, use batch generation (defined in previous steps)\n",
        "            if num_rec > 50:\n",
        "                return generate_batch_data(final_api_key, schema, num_rec, example)\n",
        "            else:\n",
        "                return generate_synthetic_data(final_api_key, schema, num_rec, example)\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=generate_wrapper,\n",
        "            inputs=[api_key_input, schema_input, num_records, example_input],\n",
        "            outputs=[dataframe_output, status_output, csv_output]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### ðŸ’¡ Tips:\n",
        "        - **JSON Mode**: Gemini 1.5 Flash is highly optimized for structured data.\n",
        "        - **Specifics**: Be specific about ranges (e.g., \"Age between 21 and 65\").\n",
        "        - **Batching**: Large requests (>50 records) are automatically split to ensure quality.\n",
        "        - **API Cost**: Gemini 1.5 Flash is currently free (within rate limits) in many regions.\n",
        "\n",
        "        ### ðŸ”‘ API Key Setup in Colab:\n",
        "        1. Click the **Key icon (Secrets)** on the left sidebar.\n",
        "        2. Add a new secret named `GEMINI_API_KEY`.\n",
        "        3. Paste your key from [Google AI Studio](https://aistudio.google.com/).\n",
        "        4. Enable \"Notebook access\" for that key.\n",
        "        \"\"\")\n",
        "\n",
        "    return demo"
      ],
      "metadata": {
        "id": "_Ns2U8kmEHil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio import themes\n",
        "# 5. Launch the App\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_interface()\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "OHjYnxkCELas",
        "outputId": "e84b565e-41fe-467d-e026-ce1954540029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3728467288.py:4: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"Synthetic Dataset Generator\", theme=gr.themes.Base()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b4da2027e1ee849ba0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b4da2027e1ee849ba0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}